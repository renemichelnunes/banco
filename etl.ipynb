{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Configuração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/Documents/Banco de dados/Avaliação 1/.venv/lib/python3.11/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth, quarter\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when, lit\n",
    "import psycopg2\n",
    "\n",
    "# Configurar a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-8.2-506.jdbc3.jar\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os data frames das tabelas\n",
    "query_products = \"select * from products\"\n",
    "query_categories = \"select * from categories\"\n",
    "query_suppliers = \"select * from suppliers\"\n",
    "query_sales_items = \"select * from sales_items\"\n",
    "query_sales = \"select * from sales\"\n",
    "query_sellers = \"select * from sellers\"\n",
    "query_customers = \"select * from customers\"\n",
    "\n",
    "def read_from_postgresql(query, table_name):\n",
    "    return sqlContext.read.format('jdbc').options(\n",
    "        url='jdbc:postgresql://localhost/fatorv',\n",
    "        dbtable='({}) as {}'.format(query, table_name),\n",
    "        user='fatorv',\n",
    "        password='123456',\n",
    "        driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_products = read_from_postgresql(query_products, \"products\")\n",
    "df_suppliers = read_from_postgresql(query_suppliers, \"suppliers\")\n",
    "df_categories = read_from_postgresql(query_categories, \"categories\")\n",
    "df_sales_items = read_from_postgresql(query_sales_items, \"sales_items\")\n",
    "df_sales = read_from_postgresql(query_sales, \"sales\")\n",
    "df_sellers = read_from_postgresql(query_sellers, \"sellers\")\n",
    "df_customers = read_from_postgresql(query_customers, \"customers\")\n",
    "\n",
    "states_schema = StructType([\n",
    "    StructField(\"id_uf\", IntegerType(), False),\n",
    "    StructField(\"sigla_uf\", StringType(), False),\n",
    "    StructField(\"state_code\", StringType(), False),\n",
    "    StructField(\"nome_uf\", StringType(), False),\n",
    "    StructField(\"id_regiao\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "regions_schema = StructType([\n",
    "    StructField(\"id_regiao\", IntegerType(), False),\n",
    "    StructField(\"sigla_regiao\", StringType(), False),\n",
    "    StructField(\"nome_regiao\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Tabela regions\n",
    "df_regions = spark.read.option(\"multiline\", \"true\").schema(regions_schema).json(\"regioes.json\")\n",
    "df_regions = df_regions.withColumnRenamed(\"id_regiao\", \"region_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_regiao\", \"region_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_regiao\", \"region_name\")\n",
    "\n",
    "# Tabela states\n",
    "df_states = spark.read.option(\"multiline\", \"true\").schema(states_schema).json(\"estados.json\")\n",
    "df_states = df_states.withColumnRenamed(\"id_uf\", \"state_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_uf\", \"state_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_uf\", \"state_name\") \\\n",
    "                     .withColumnRenamed(\"id_regiao\", \"region_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformação<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando os dados das tabelas, construindo a tabela fatos\n",
    "\n",
    "# Join states com regions\n",
    "df_dim_states = df_states.join(df_regions, \"region_id\")\n",
    "#df_dim_states.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em suppliers\n",
    "df_dim_suppliers = df_suppliers.withColumn(\"email\", upper(df_suppliers[\"email\"])) \\\n",
    "                           .withColumn(\"supplier_name\", upper(df_suppliers[\"supplier_name\"]))\n",
    "df_dim_suppliers = df_dim_suppliers.join(df_dim_states.select(\"state_id\", \"state_acronym\"), df_dim_states[\"state_acronym\"] == df_dim_suppliers[\"state\"])\\\n",
    "    .withColumnRenamed(\"state_id\", \"supplier_state_id\")\n",
    "\n",
    "#df_dim_suppliers.show()\n",
    "\n",
    "# Cria dim_date e coluna date_id\n",
    "df_dim_date = df_sales.select(\"date\").distinct().withColumn(\"date_id\", monotonically_increasing_id() + 1) \\\n",
    "                .withColumn(\"date_id\", col(\"date_id\").cast(\"numeric(8,0)\"))\n",
    "\n",
    "# Divide date em year, month, day\n",
    "df_dim_date = df_dim_date.withColumn(\"year\", year(\"date\")).withColumn(\"year\", col(\"year\").cast(\"numeric(4,0)\")) \\\n",
    "                   .withColumn(\"month\", month(\"date\")).withColumn(\"month\", col(\"month\").cast(\"numeric(2,0)\")) \\\n",
    "                   .withColumn(\"day\", dayofmonth(\"date\")).withColumn(\"day\", col(\"day\").cast(\"numeric(2,0)\")) \\\n",
    "                   .withColumn(\"quarter\", quarter(\"date\")).withColumn(\"quarter\", col(\"quarter\").cast(\"numeric(1,0)\"))\n",
    "#df_dim_date.show()\n",
    "\n",
    "# Muda o formato da data\n",
    "df_dim_date = df_dim_date.withColumn(\"date\", date_format(\"date\", \"yyyyMMdd\"))\n",
    "\n",
    "# Adiciona o nome dos meses\n",
    "df_dim_date = df_dim_date.withColumn(\"month_name\", \n",
    "                   when(df_dim_date.month == 1, lit(\"January\"))\n",
    "                   .when(df_dim_date.month == 2, lit(\"February\"))\n",
    "                   .when(df_dim_date.month == 3, lit(\"March\"))\n",
    "                   .when(df_dim_date.month == 4, lit(\"April\"))\n",
    "                   .when(df_dim_date.month == 5, lit(\"May\"))\n",
    "                   .when(df_dim_date.month == 6, lit(\"June\"))\n",
    "                   .when(df_dim_date.month == 7, lit(\"July\"))\n",
    "                   .when(df_dim_date.month == 8, lit(\"August\"))\n",
    "                   .when(df_dim_date.month == 9, lit(\"September\"))\n",
    "                   .when(df_dim_date.month == 10, lit(\"October\"))\n",
    "                   .when(df_dim_date.month == 11, lit(\"November\"))\n",
    "                   .when(df_dim_date.month == 12, lit(\"December\"))\n",
    "                   .otherwise(None))\n",
    "#df_dim_date.show()\n",
    "\n",
    "# Join df_sales com df_date\n",
    "df_sales = df_sales.withColumn(\"date\", date_format(\"date\", \"yyyyMMdd\"))\n",
    "df_sales = df_sales.join(df_dim_date.select(\"date_id\", \"date\"), \"date\")\n",
    "df_sales.drop(\"date\")\n",
    "df_dim_sales = df_sales.select(\"sales_id\", \"customer_id\", \"seller_id\", \"date_id\", \"total_price\")\n",
    "#df_dim_sales.show()\n",
    "\n",
    "# Criando df_dim_suppliers e trocando a coluna states por states_id\n",
    "df_suppliers = df_suppliers.join(df_states.select(\"state_id\", \"state_acronym\"), df_suppliers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\\\n",
    "    .withColumnRenamed(\"state_id\", \"supplier_state_id\")\n",
    "df_suppliers = df_suppliers.drop(\"state\")\n",
    "#df_suppliers.show()\n",
    "\n",
    "# Criando df_dim_sellers fazendo upper em supplier_name e email em sellers\n",
    "df_dim_sellers = df_sellers.withColumn(\"email\", upper(df_sellers[\"email\"])) \\\n",
    "                       .withColumn(\"seller_name\", upper(df_sellers[\"seller_name\"]))\n",
    "\n",
    "# Join sellers com states, troca a coluna states por states_id\n",
    "df_dim_sellers = df_dim_sellers.join(df_dim_states.select(\"state_id\", \"state_acronym\"), df_dim_sellers[\"state\"] == df_dim_states[\"state_acronym\"], \"inner\")\\\n",
    "    .withColumnRenamed(\"state_id\", \"seller_state_id\")\n",
    "df_dim_sellers = df_dim_sellers.drop('state', 'state_acronym')\n",
    "#df_dim_sellers.show()\n",
    "\n",
    "# Criando df_dim_customers e fazendo upper em supplier_name e email em customers\n",
    "df_dim_customers = df_customers.withColumn(\"email\", upper(df_customers[\"email\"])) \\\n",
    "                           .withColumn(\"customer_name\", upper(df_customers[\"customer_name\"]))\n",
    "\n",
    "# Join customers com states, troca a coluna states por states_id\n",
    "df_dim_customers = df_dim_customers.join(df_dim_states.select(\"state_id\", \"state_acronym\"), df_dim_customers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\\\n",
    "    .withColumnRenamed(\"state_id\", \"customer_state_id\")\n",
    "df_dim_customers = df_dim_customers.drop(\"state\", \"state_acronym\")\n",
    "#df_dim_customers.show()\n",
    "\n",
    "# Criando df_dim_products fazendo upper em product_name em products\n",
    "df_dim_products = df_products.withColumn(\"product_name\", upper(df_products[\"product_name\"]))\n",
    "\n",
    "# Criando dim_products\n",
    "df_dim_products = df_products.select(\"product_id\", \"product_name\", \"category_id\", \"supplier_id\", \"price\")\n",
    "\n",
    "# Criando df_dim_categories fazendo upper em category_name em categories\n",
    "df_dim_categories = df_categories.withColumn(\"category_name\", upper(df_categories[\"category_name\"]))\n",
    "\n",
    "# Criando a tabela fato\n",
    "fato = df_dim_sales.join(df_sales_items.select(\"sales_id\", \"product_id\", \"quantity\", \"price\"), \"sales_id\")\n",
    "fato = fato.withColumnRenamed(\"price\", \"sell_price\")\n",
    "fato = fato.join(df_dim_products.select(\"product_id\", \"category_id\", \"supplier_id\"), \"product_id\")\n",
    "fato = fato.join(df_dim_customers.select(\"customer_id\", \"customer_state_id\"), \"customer_id\")\n",
    "fato = fato.join(df_dim_sellers.select(\"seller_id\", \"seller_state_id\"), \"seller_id\")\n",
    "fato = fato.join(df_dim_suppliers.select(\"supplier_id\", \"supplier_state_id\"), \"supplier_id\")\n",
    "fato = fato.drop(\"total_price\")\n",
    "\n",
    "# Calculando sub_total = sell_price * quantity\n",
    "fato = fato.withColumn(\"sub_total\", col(\"sell_price\") * col(\"quantity\"))\n",
    "\n",
    "# Calculando total_price = sum(sub_total)\n",
    "fato = fato.join(fato.select(\"sales_id\", \"sub_total\").groupBy(\"sales_id\").sum(\"sub_total\").withColumnRenamed(\"sum(sub_total)\", \"total_price\"), \"sales_id\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Carga<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão bem-sucedida!\n"
     ]
    }
   ],
   "source": [
    "connected = False\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=\"fatorvgestao\",\n",
    "        user=\"fatorv\",\n",
    "        password=\"123456\",\n",
    "        host=\"localhost\"\n",
    "    )\n",
    "    print(\"Conexão bem-sucedida!\")\n",
    "    connected = True\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Erro ao conectar:\", e)\n",
    "    exit()\n",
    "if(connected):\n",
    "   cursor = connection.cursor()\n",
    "\n",
    "   # Limpa as tabelas\n",
    "\n",
    "   query = \"delete from fato_sales_items\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar fato_sales_items\")\n",
    "\n",
    "   query = \"delete from dim_customers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_customers\")\n",
    "   \n",
    "   query = \"delete from dim_sellers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_sellers\")\n",
    "\n",
    "   query = \"delete from dim_suppliers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_suppliers\")\n",
    "\n",
    "   query = \"delete from dim_states\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_states\")\n",
    "\n",
    "   query = \"delete from dim_products\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_products\")\n",
    "\n",
    "   query = \"delete from dim_categories\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_categories\")\n",
    "   \n",
    "   query = \"delete from dim_date\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_date\")\n",
    "   \n",
    "   connection.commit()\n",
    "\n",
    "# Insere os dados\n",
    "try:\n",
    "   # dim_categories\n",
    "   data = df_dim_categories.collect()\n",
    "   insert_values = [(row['category_id'], row['category_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_categories (category_id, category_name) VALUES (%s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_customers\n",
    "   data = df_dim_customers.collect()\n",
    "   insert_values = [(row['customer_id'], row['customer_name'], row['email'], row['customer_state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_customers (customer_id, customer_name, email, customer_state_id) VALUES (%s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_date\n",
    "   data = df_dim_date.collect()\n",
    "   insert_values = [(row['date_id'], row['date'], row['year'], row['month'], row['quarter'], row['day'], row['month_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_date (date_id, date, year, month, quarter, day, month_name) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_products\n",
    "   data = df_dim_products.collect()\n",
    "   insert_values = [(row['product_id'], row['product_name'], row['price']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_products (product_id, product_name, price) VALUES (%s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_sellers\n",
    "   data = df_dim_sellers.collect()\n",
    "   insert_values = [(row['seller_id'], row['seller_name'], row['email'], row['tx_commission'], row['seller_state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_sellers (seller_id, seller_name, email, tx_commission, seller_state_id) VALUES (%s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_states\n",
    "   data = df_dim_states.collect()\n",
    "   insert_values = [(row['state_id'], row['state_acronym'], row['state_code'], row['state_name'], row['region_id'], row['region_acronym'], row['region_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_states (state_id, state_acronym, state_code, state_name, region_id, region_acronym, region_name) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_suppliers\n",
    "   data = df_dim_suppliers.collect()\n",
    "   insert_values = [(row['supplier_id'], row['supplier_name'], row['email'], row['supplier_state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_suppliers (supplier_id, supplier_name, email, supplier_state_id) VALUES (%s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # fato_sales_items\n",
    "   data = fato.collect()\n",
    "   insert_values = [(row['sales_id'], row['product_id'], row['date_id'], row['customer_id'], row['seller_id'], row['total_price'],\n",
    "                     row['supplier_id'], row['customer_state_id'], row['seller_state_id'], row['supplier_state_id'], \n",
    "                     row['category_id'], row['quantity'], row['sell_price'], row['sub_total']) for row in data]\n",
    "   insert_query = \"\"\"INSERT INTO fato_sales_items (sales_id, product_id, date_id, customer_id, seller_id, total_price, supplier_id,\n",
    "                                                   customer_state_id, seller_state_id, supplier_state_id, category_id, quantity, \n",
    "                                                   sell_price, sub_total) \n",
    "                     VALUES (%s, %s, %s, %s,%s, %s, %s, %s,%s, %s, %s, %s, %s, %s)\"\"\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   connection.commit()\n",
    "except psycopg2.Error as e:\n",
    "   print(\"erro - \", e)\n",
    "\n",
    "connection.close()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
