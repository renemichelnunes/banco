{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Configuração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/Documents/Banco de dados/Avaliação 1/.venv/lib/python3.11/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# Configurar a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-8.2-506.jdbc3.jar\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os data frames das tabelas\n",
    "query_products = \"select * from products\"\n",
    "query_categories = \"select * from categories\"\n",
    "query_suppliers = \"select * from suppliers\"\n",
    "query_sales_items = \"select * from sales_items\"\n",
    "query_sales = \"select * from sales\"\n",
    "query_sellers = \"select * from sellers\"\n",
    "query_customers = \"select * from customers\"\n",
    "\n",
    "\n",
    "df_products = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as products'.format(query_products),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_suppliers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as suppliers'.format(query_suppliers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_categories = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as categories'.format(query_categories),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales_items = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales_items'.format(query_sales_items),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales'.format(query_sales),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sellers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sellers'.format(query_sellers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_customers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as customers'.format(query_customers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "states_schema = StructType([\n",
    "    StructField(\"id_uf\", IntegerType(), False),\n",
    "    StructField(\"sigla_uf\", StringType(), False),\n",
    "    StructField(\"state_code\", StringType(), False),\n",
    "    StructField(\"nome_uf\", StringType(), False),\n",
    "    StructField(\"id_regiao\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "regions_schema = StructType([\n",
    "    StructField(\"id_regiao\", IntegerType(), False),\n",
    "    StructField(\"sigla_regiao\", StringType(), False),\n",
    "    StructField(\"nome_regiao\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Tabela regions\n",
    "df_regions = spark.read.option(\"multiline\", \"true\").schema(regions_schema).json(\"regioes.json\")\n",
    "df_regions = df_regions.withColumnRenamed(\"id_regiao\", \"region_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_regiao\", \"region_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_regiao\", \"region_name\")\n",
    "\n",
    "# Tabela states\n",
    "df_states = spark.read.option(\"multiline\", \"true\").schema(states_schema).json(\"estados.json\")\n",
    "df_states = df_states.withColumnRenamed(\"id_uf\", \"state_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_uf\", \"state_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_uf\", \"state_name\") \\\n",
    "                     .withColumnRenamed(\"id_regiao\", \"region_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformação<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+---+-------+-------+----------+\n",
      "|    date|year|month|day|date_id|quarter|month_name|\n",
      "+--------+----+-----+---+-------+-------+----------+\n",
      "|20220820|2022|    8| 20|      1|      3|    August|\n",
      "|20230515|2023|    5| 15|      2|      2|       May|\n",
      "+--------+----+-----+---+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alterando os dados das tabelas, construindo a tabela fatos\n",
    "\n",
    "# Join states com regions\n",
    "df_joined_st_re = df_states.join(df_regions, \"region_id\")\n",
    "#df_joined_st_re.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em suppliers\n",
    "df_suppliers = df_suppliers.withColumn(\"email\", upper(df_suppliers[\"email\"])) \\\n",
    "                           .withColumn(\"supplier_name\", upper(df_suppliers[\"supplier_name\"]))\n",
    "\n",
    "# Divide a date em year, month, day\n",
    "df_sales = df_sales.withColumn(\"year\", year(\"date\")) \\\n",
    "                   .withColumn(\"month\", month(\"date\")) \\\n",
    "                   .withColumn(\"day\", dayofmonth(\"date\"))\n",
    "\n",
    "# Muda o formato da data\n",
    "df_sales = df_sales.withColumn(\"date\", date_format(\"date\", \"yyyyMMdd\"))\n",
    "\n",
    "# Criar df_date\n",
    "df_date = df_sales.select(\"date\", \"year\", \"month\", \"day\").distinct()\n",
    "df_date = df_sales.select(\"date\", \"year\", \"month\", \"day\").distinct() \\\n",
    "                  .withColumn(\"date_id\", monotonically_increasing_id() + 1)\n",
    "df_date = df_date.withColumn(\"date\", col(\"date\").cast(\"integer\")) \\\n",
    "                 .withColumn(\"date_id\", col(\"date_id\").cast(\"integer\"))\n",
    "\n",
    "\n",
    "# Criar coluna quarter(trimestre)\n",
    "quarter = when(df_date[\"month\"].between(1,3), 1) \\\n",
    "          .when(df_date[\"month\"].between(4,6), 2) \\\n",
    "          .when(df_date[\"month\"].between(7,9), 3) \\\n",
    "          .otherwise(4)\n",
    "df_date = df_date.withColumn(\"quarter\", quarter)\n",
    "\n",
    "# Adiciona o nome dos meses\n",
    "df_date = df_date.withColumn(\"month_name\", \n",
    "                   when(df_date.month == 1, lit(\"January\"))\n",
    "                   .when(df_date.month == 2, lit(\"February\"))\n",
    "                   .when(df_date.month == 3, lit(\"March\"))\n",
    "                   .when(df_date.month == 4, lit(\"April\"))\n",
    "                   .when(df_date.month == 5, lit(\"May\"))\n",
    "                   .when(df_date.month == 6, lit(\"June\"))\n",
    "                   .when(df_date.month == 7, lit(\"July\"))\n",
    "                   .when(df_date.month == 8, lit(\"August\"))\n",
    "                   .when(df_date.month == 9, lit(\"September\"))\n",
    "                   .when(df_date.month == 10, lit(\"October\"))\n",
    "                   .when(df_date.month == 11, lit(\"November\"))\n",
    "                   .when(df_date.month == 12, lit(\"December\"))\n",
    "                   .otherwise(None))\n",
    "#df_date.show()\n",
    "\n",
    "# Join df_sales com df_date\n",
    "df_sales = df_sales.join(df_date, \"date\")\n",
    "df_sales = df_sales.select(\"sales_id\", \"customer_id\", \"seller_id\", \"date_id\", \"total_price\")\n",
    "#df_sales.show()\n",
    "\n",
    "# Join suppliers com states, troca a coluna states por states_id\n",
    "df_joined_sup_st = df_suppliers.join(df_states, df_suppliers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_suppliers = df_joined_sup_st.select(\"supplier_id\", \"supplier_name\", \"email\",\"state_id\")\n",
    "#df_suppliers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em sellers\n",
    "df_sellers = df_sellers.withColumn(\"email\", upper(df_sellers[\"email\"])) \\\n",
    "                       .withColumn(\"seller_name\", upper(df_sellers[\"seller_name\"]))\n",
    "\n",
    "# Join sellers com states, troca a coluna states por states_id\n",
    "df_joined_se_st = df_sellers.join(df_states, df_sellers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_sellers = df_joined_se_st.select(\"seller_id\", \"seller_name\", \"email\", \"tx_commission\",\"state_id\")\n",
    "#df_sellers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em customers\n",
    "df_customers = df_customers.withColumn(\"email\", upper(df_customers[\"email\"])) \\\n",
    "                           .withColumn(\"customer_name\", upper(df_customers[\"customer_name\"]))\n",
    "\n",
    "# Join customers com states, troca a coluna states por states_id\n",
    "df_joined_cu_st = df_customers.join(df_states, df_customers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_customers = df_joined_cu_st.select(\"customer_id\", \"customer_name\", \"email\",\"state_id\")\n",
    "#df_customers.show()\n",
    "\n",
    "# Fazendo upper em product_name em products\n",
    "df_products = df_products.withColumn(\"product_name\", upper(df_products[\"product_name\"]))\n",
    "\n",
    "# Join entre products e suppliers\n",
    "df_products = df_products.drop(\"price\")\n",
    "df_joined_products_suppliers = df_products.join(df_suppliers, \"supplier_id\")\n",
    "#df_joined_products_suppliers.show()\n",
    "\n",
    "# Fazendo upper em category_name em categories\n",
    "df_categories = df_categories.withColumn(\"category_name\", upper(df_categories[\"category_name\"]))\n",
    "\n",
    "# Join com categories\n",
    "df_joined_products_suppliers_categories = df_joined_products_suppliers.join(df_categories, \"category_id\")\n",
    "#df_joined_products_suppliers_categories.show()\n",
    "\n",
    "#Join com sales_items\n",
    "df_sales_items = df_sales_items.withColumn(\"sell_price\", df_sales_items[\"price\"])\n",
    "df_joined_prod_sup_cat_si = df_joined_products_suppliers_categories.join(df_sales_items, \"product_id\")\n",
    "#df_joined_prod_sup_cat_si.show()\n",
    "\n",
    "#join com sales\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si.join(df_sales, \"sales_id\")\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "\n",
    "# Calculando sub_total = sell_price * quantity\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sub_total\", col(\"sell_price\") * col(\"quantity\"))\n",
    "\n",
    "# Calculando total_price = sum(sub_total)\n",
    "df_joined_prod_sup_cat_si_sa.createOrReplaceTempView(\"sales_data\")\n",
    "result = spark.sql(\"\"\"\n",
    "    select \n",
    "        sales_id,\n",
    "        sum(sub_total) as total_price_2\n",
    "    from\n",
    "        sales_data\n",
    "    group by\n",
    "        sales_id\n",
    "\"\"\")\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.join(result, \"sales_id\", \"inner\") \\\n",
    ".withColumn(\"total_price\", result[\"total_price_2\"])\n",
    "\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.select(\"sales_id\", \"product_id\", \"date_id\", \"customer_id\", \"seller_id\", \n",
    "                                                                   \"total_price\", \"supplier_id\", \"state_id\", \"category_id\", \"quantity\", \n",
    "                                                                   \"sell_price\", \"sub_total\")\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"total_price\", col(\"total_price\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sell_price\", col(\"sell_price\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sub_total\", col(\"sub_total\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"date_id\", col(\"date_id\").cast(\"integer\"))\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "#df_joined_prod_sup_cat_si_sa.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Carga<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_url = \"jdbc:postgresql://localhost:5432/fatorvgestao2\"\n",
    "properties = {\n",
    "    \"user\": \"fatorv\",\n",
    "    \"password\": \"123456\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"url\" : postgres_url\n",
    "}\n",
    "\n",
    "df_categories.write.jdbc(postgres_url, \"dim_categories\", \"overwrite\", properties)\n",
    "df_customers.write.jdbc(postgres_url, \"dim_customers\", \"overwrite\", properties)\n",
    "df_sellers.write.jdbc(postgres_url, \"dim_sellers\", \"overwrite\", properties)\n",
    "df_suppliers.write.jdbc(postgres_url, \"dim_suppliers\", \"overwrite\", properties)\n",
    "df_date.write.jdbc(postgres_url, \"dim_date\", \"overwrite\", properties)\n",
    "df_joined_st_re.write.jdbc(postgres_url, \"dim_states\", \"overwrite\", properties)\n",
    "df_products.write.jdbc(postgres_url, \"dim_products\", \"overwrite\", properties)\n",
    "df_joined_prod_sup_cat_si_sa.write.jdbc(postgres_url, \"fato_sales_items\", \"overwrite\", properties)\n",
    "\n",
    "# Fecha a sessão do Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
