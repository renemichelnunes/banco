{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Configuração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when, lit\n",
    "import psycopg2\n",
    "\n",
    "# Configurar a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-8.2-506.jdbc3.jar\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os data frames das tabelas\n",
    "query_products = \"select * from products\"\n",
    "query_categories = \"select * from categories\"\n",
    "query_suppliers = \"select * from suppliers\"\n",
    "query_sales_items = \"select * from sales_items\"\n",
    "query_sales = \"select * from sales\"\n",
    "query_sellers = \"select * from sellers\"\n",
    "query_customers = \"select * from customers\"\n",
    "\n",
    "\n",
    "df_products = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as products'.format(query_products),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_suppliers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as suppliers'.format(query_suppliers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_categories = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as categories'.format(query_categories),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales_items = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales_items'.format(query_sales_items),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales'.format(query_sales),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sellers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sellers'.format(query_sellers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_customers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as customers'.format(query_customers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "states_schema = StructType([\n",
    "    StructField(\"id_uf\", IntegerType(), False),\n",
    "    StructField(\"sigla_uf\", StringType(), False),\n",
    "    StructField(\"state_code\", StringType(), False),\n",
    "    StructField(\"nome_uf\", StringType(), False),\n",
    "    StructField(\"id_regiao\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "regions_schema = StructType([\n",
    "    StructField(\"id_regiao\", IntegerType(), False),\n",
    "    StructField(\"sigla_regiao\", StringType(), False),\n",
    "    StructField(\"nome_regiao\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Tabela regions\n",
    "df_regions = spark.read.option(\"multiline\", \"true\").schema(regions_schema).json(\"regioes.json\")\n",
    "df_regions = df_regions.withColumnRenamed(\"id_regiao\", \"region_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_regiao\", \"region_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_regiao\", \"region_name\")\n",
    "\n",
    "# Tabela states\n",
    "df_states = spark.read.option(\"multiline\", \"true\").schema(states_schema).json(\"estados.json\")\n",
    "df_states = df_states.withColumnRenamed(\"id_uf\", \"state_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_uf\", \"state_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_uf\", \"state_name\") \\\n",
    "                     .withColumnRenamed(\"id_regiao\", \"region_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformação<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando os dados das tabelas, construindo a tabela fatos\n",
    "\n",
    "# Join states com regions\n",
    "df_joined_st_re = df_states.join(df_regions, \"region_id\")\n",
    "#df_joined_st_re.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em suppliers\n",
    "df_suppliers = df_suppliers.withColumn(\"email\", upper(df_suppliers[\"email\"])) \\\n",
    "                           .withColumn(\"supplier_name\", upper(df_suppliers[\"supplier_name\"]))\n",
    "\n",
    "# Divide a date em year, month, day\n",
    "df_sales = df_sales.withColumn(\"year\", year(\"date\")) \\\n",
    "                   .withColumn(\"month\", month(\"date\")) \\\n",
    "                   .withColumn(\"day\", dayofmonth(\"date\"))\n",
    "\n",
    "# Muda o formato da data\n",
    "df_sales = df_sales.withColumn(\"date\", date_format(\"date\", \"yyyyMMdd\"))\n",
    "\n",
    "# Criar df_date\n",
    "df_date = df_sales.select(\"date\", \"year\", \"month\", \"day\").distinct()\n",
    "df_date = df_sales.select(\"date\", \"year\", \"month\", \"day\").distinct() \\\n",
    "                  .withColumn(\"date_id\", monotonically_increasing_id() + 1)\n",
    "df_date = df_date.withColumn(\"date\", col(\"date\").cast(\"integer\")) \\\n",
    "                 .withColumn(\"date_id\", col(\"date_id\").cast(\"integer\"))\n",
    "\n",
    "\n",
    "# Criar coluna quarter(trimestre)\n",
    "quarter = when(df_date[\"month\"].between(1,3), 1) \\\n",
    "          .when(df_date[\"month\"].between(4,6), 2) \\\n",
    "          .when(df_date[\"month\"].between(7,9), 3) \\\n",
    "          .otherwise(4)\n",
    "df_date = df_date.withColumn(\"quarter\", quarter)\n",
    "\n",
    "# Adiciona o nome dos meses\n",
    "df_date = df_date.withColumn(\"month_name\", \n",
    "                   when(df_date.month == 1, lit(\"January\"))\n",
    "                   .when(df_date.month == 2, lit(\"February\"))\n",
    "                   .when(df_date.month == 3, lit(\"March\"))\n",
    "                   .when(df_date.month == 4, lit(\"April\"))\n",
    "                   .when(df_date.month == 5, lit(\"May\"))\n",
    "                   .when(df_date.month == 6, lit(\"June\"))\n",
    "                   .when(df_date.month == 7, lit(\"July\"))\n",
    "                   .when(df_date.month == 8, lit(\"August\"))\n",
    "                   .when(df_date.month == 9, lit(\"September\"))\n",
    "                   .when(df_date.month == 10, lit(\"October\"))\n",
    "                   .when(df_date.month == 11, lit(\"November\"))\n",
    "                   .when(df_date.month == 12, lit(\"December\"))\n",
    "                   .otherwise(None))\n",
    "#df_date.show()\n",
    "\n",
    "# Join df_sales com df_date\n",
    "df_sales = df_sales.join(df_date, \"date\")\n",
    "df_sales = df_sales.select(\"sales_id\", \"customer_id\", \"seller_id\", \"date_id\", \"total_price\")\n",
    "#df_sales.show()\n",
    "\n",
    "# Join suppliers com states, troca a coluna states por states_id\n",
    "df_joined_sup_st = df_suppliers.join(df_states, df_suppliers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_suppliers = df_joined_sup_st.select(\"supplier_id\", \"supplier_name\", \"email\",\"state_id\")\n",
    "#df_suppliers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em sellers\n",
    "df_sellers = df_sellers.withColumn(\"email\", upper(df_sellers[\"email\"])) \\\n",
    "                       .withColumn(\"seller_name\", upper(df_sellers[\"seller_name\"]))\n",
    "\n",
    "# Join sellers com states, troca a coluna states por states_id\n",
    "df_joined_se_st = df_sellers.join(df_states, df_sellers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_sellers = df_joined_se_st.select(\"seller_id\", \"seller_name\", \"email\", \"tx_commission\",\"state_id\")\n",
    "#df_sellers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em customers\n",
    "df_customers = df_customers.withColumn(\"email\", upper(df_customers[\"email\"])) \\\n",
    "                           .withColumn(\"customer_name\", upper(df_customers[\"customer_name\"]))\n",
    "\n",
    "# Join customers com states, troca a coluna states por states_id\n",
    "df_joined_cu_st = df_customers.join(df_states, df_customers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_customers = df_joined_cu_st.select(\"customer_id\", \"customer_name\", \"email\",\"state_id\")\n",
    "#df_customers.show()\n",
    "\n",
    "# Fazendo upper em product_name em products\n",
    "df_products = df_products.withColumn(\"product_name\", upper(df_products[\"product_name\"]))\n",
    "\n",
    "# Criando dim_products\n",
    "df_dim_products = df_products.select(\"product_id\", \"product_name\", \"price\")\n",
    "\n",
    "# Join entre products e suppliers\n",
    "df_products = df_products.drop(\"price\")\n",
    "df_joined_products_suppliers = df_products.join(df_suppliers, \"supplier_id\")\n",
    "#df_joined_products_suppliers.show()\n",
    "\n",
    "# Fazendo upper em category_name em categories\n",
    "df_categories = df_categories.withColumn(\"category_name\", upper(df_categories[\"category_name\"]))\n",
    "\n",
    "# Join com categories\n",
    "df_joined_products_suppliers_categories = df_joined_products_suppliers.join(df_categories, \"category_id\")\n",
    "#df_joined_products_suppliers_categories.show()\n",
    "\n",
    "#Join com sales_items\n",
    "df_sales_items = df_sales_items.withColumn(\"sell_price\", df_sales_items[\"price\"])\n",
    "df_joined_prod_sup_cat_si = df_joined_products_suppliers_categories.join(df_sales_items, \"product_id\")\n",
    "#df_joined_prod_sup_cat_si.show()\n",
    "\n",
    "#join com sales\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si.join(df_sales, \"sales_id\")\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "\n",
    "# Calculando sub_total = sell_price * quantity\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sub_total\", col(\"sell_price\") * col(\"quantity\"))\n",
    "\n",
    "# Calculando total_price = sum(sub_total)\n",
    "df_joined_prod_sup_cat_si_sa.createOrReplaceTempView(\"sales_data\")\n",
    "result = spark.sql(\"\"\"\n",
    "    select \n",
    "        sales_id,\n",
    "        sum(sub_total) as total_price_2\n",
    "    from\n",
    "        sales_data\n",
    "    group by\n",
    "        sales_id\n",
    "\"\"\")\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.join(result, \"sales_id\", \"inner\") \\\n",
    ".withColumn(\"total_price\", result[\"total_price_2\"])\n",
    "\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.select(\"sales_id\", \"product_id\", \"date_id\", \"customer_id\", \"seller_id\", \n",
    "                                                                   \"total_price\", \"supplier_id\", \"state_id\", \"category_id\", \"quantity\", \n",
    "                                                                   \"sell_price\", \"sub_total\")\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"total_price\", col(\"total_price\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sell_price\", col(\"sell_price\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"sub_total\", col(\"sub_total\").cast(\"decimal(10,2)\"))\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"date_id\", col(\"date_id\").cast(\"integer\"))\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "#df_joined_prod_sup_cat_si_sa.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Carga<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão bem-sucedida!\n"
     ]
    }
   ],
   "source": [
    "connected = False\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=\"fatorvgestao\",\n",
    "        user=\"fatorv\",\n",
    "        password=\"123456\",\n",
    "        host=\"localhost\"\n",
    "    )\n",
    "    print(\"Conexão bem-sucedida!\")\n",
    "    connected = True\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Erro ao conectar:\", e)\n",
    "    exit()\n",
    "if(connected):\n",
    "   cursor = connection.cursor()\n",
    "\n",
    "   # Limpa as tabelas\n",
    "\n",
    "   query = \"delete from fato_sales_items\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar fato_sales_items\")\n",
    "\n",
    "   query = \"delete from dim_customers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_customers\")\n",
    "   \n",
    "   query = \"delete from dim_sellers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_sellers\")\n",
    "\n",
    "   query = \"delete from dim_suppliers\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_suppliers\")\n",
    "\n",
    "   query = \"delete from dim_states\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_states\")\n",
    "\n",
    "   query = \"delete from dim_products\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_products\")\n",
    "\n",
    "   query = \"delete from dim_categories\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_categories\")\n",
    "   \n",
    "   query = \"delete from dim_date\"\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "   except psycopg2.Error as e:\n",
    "      print(\"erro ao limpar dim_date\")\n",
    "   \n",
    "   connection.commit()\n",
    "\n",
    "# Insere os dados\n",
    "try:\n",
    "   # dim_categories\n",
    "   data = df_categories.collect()\n",
    "   insert_values = [(row['category_id'], row['category_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_categories (category_id, category_name) VALUES (%s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_customers\n",
    "   data = df_customers.collect()\n",
    "   insert_values = [(row['customer_id'], row['customer_name'], row['email'], row['state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_customers (customer_id, customer_name, email, state_id) VALUES (%s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_date\n",
    "   data = df_date.collect()\n",
    "   insert_values = [(row['date_id'], row['date'], row['year'], row['month'], row['quarter'], row['day'], row['month_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_date (date_id, date, year, month, quarter, day, month_name) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_products\n",
    "   data = df_dim_products.collect()\n",
    "   insert_values = [(row['product_id'], row['product_name'], row['price']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_products (product_id, product_name, price) VALUES (%s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_sellers\n",
    "   data = df_sellers.collect()\n",
    "   insert_values = [(row['seller_id'], row['seller_name'], row['email'], row['tx_commission'], row['state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_sellers (seller_id, seller_name, email, tx_commission, state_id) VALUES (%s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_states\n",
    "   data = df_joined_st_re.collect()\n",
    "   insert_values = [(row['state_id'], row['state_acronym'], row['state_code'], row['state_name'], row['region_id'], row['region_acronym'], row['region_name']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_states (state_id, state_acronym, state_code, state_name, region_id, region_acronym, region_name) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # dim_suppliers\n",
    "   data = df_suppliers.collect()\n",
    "   insert_values = [(row['supplier_id'], row['supplier_name'], row['email'], row['state_id']) for row in data]\n",
    "   insert_query = \"INSERT INTO dim_suppliers (supplier_id, supplier_name, email, state_id) VALUES (%s, %s, %s, %s)\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   # fato_sales_items\n",
    "   data = df_joined_prod_sup_cat_si_sa.collect()\n",
    "   insert_values = [(row['sales_id'], row['product_id'], row['date_id'], row['customer_id'], row['seller_id'], row['total_price'],\n",
    "                     row['supplier_id'], row['state_id'], row['category_id'], row['quantity'], row['sell_price'], row['sub_total']) for row in data]\n",
    "   insert_query = \"\"\"INSERT INTO fato_sales_items (sales_id, product_id, date_id, customer_id, seller_id, total_price, supplier_id,\n",
    "                                                   state_id, category_id, quantity, sell_price, sub_total) VALUES (%s, %s, %s, %s,%s, %s, %s, %s,%s, %s, %s, %s)\"\"\"\n",
    "   cursor.executemany(insert_query, insert_values)\n",
    "\n",
    "   connection.commit()\n",
    "except psycopg2.Error as e:\n",
    "   print(\"erro - \", e)\n",
    "\n",
    "connection.close()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
