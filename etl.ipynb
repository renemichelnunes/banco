{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Configuração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "# Configurar a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-8.2-506.jdbc3.jar\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "# Conectar ao banco de dados usando psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"fatorv\",\n",
    "    user=\"fatorv\",\n",
    "    password=\"123456\",\n",
    "    host=\"localhost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extração<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os data frames das tabelas\n",
    "query_products = \"select * from products\"\n",
    "query_categories = \"select * from categories\"\n",
    "query_suppliers = \"select * from suppliers\"\n",
    "query_sales_items = \"select * from sales_items\"\n",
    "query_sales = \"select * from sales\"\n",
    "query_sellers = \"select * from sellers\"\n",
    "query_customers = \"select * from customers\"\n",
    "\n",
    "\n",
    "df_products = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as products'.format(query_products),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_suppliers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as suppliers'.format(query_suppliers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_categories = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as categories'.format(query_categories),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales_items = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales_items'.format(query_sales_items),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sales = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sales'.format(query_sales),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_sellers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as sellers'.format(query_sellers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "df_customers = sqlContext.read.format('jdbc').options(\n",
    "    url='jdbc:postgresql://localhost/fatorv',\n",
    "    dbtable='({}) as customers'.format(query_customers),\n",
    "    user='fatorv',\n",
    "    password='123456',\n",
    "    driver='org.postgresql.Driver').load()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "states_schema = StructType([\n",
    "    StructField(\"id_uf\", IntegerType(), False),\n",
    "    StructField(\"sigla_uf\", StringType(), False),\n",
    "    StructField(\"state_code\", StringType(), False),\n",
    "    StructField(\"nome_uf\", StringType(), False),\n",
    "    StructField(\"id_regiao\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "regions_schema = StructType([\n",
    "    StructField(\"id_regiao\", IntegerType(), False),\n",
    "    StructField(\"sigla_regiao\", StringType(), False),\n",
    "    StructField(\"nome_regiao\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Tabela regions\n",
    "df_regions = spark.read.option(\"multiline\", \"true\").schema(regions_schema).json(\"regioes.json\")\n",
    "df_regions = df_regions.withColumnRenamed(\"id_regiao\", \"region_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_regiao\", \"region_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_regiao\", \"region_name\")\n",
    "\n",
    "# Tabela states\n",
    "df_states = spark.read.option(\"multiline\", \"true\").schema(states_schema).json(\"estados.json\")\n",
    "df_states = df_states.withColumnRenamed(\"id_uf\", \"state_id\") \\\n",
    "                     .withColumnRenamed(\"sigla_uf\", \"state_acronym\") \\\n",
    "                     .withColumnRenamed(\"nome_uf\", \"state_name\") \\\n",
    "                     .withColumnRenamed(\"id_regiao\", \"region_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformação<h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando os dados das tabelas, construindo a tabela fatos\n",
    "\n",
    "# Join states com regions\n",
    "df_joined_st_re = df_states.join(df_regions, \"region_id\")\n",
    "#df_joined_st_re.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em suppliers\n",
    "df_suppliers = df_suppliers.withColumn(\"email\", upper(df_suppliers[\"email\"])) \\\n",
    "                           .withColumn(\"supplier_name\", upper(df_suppliers[\"supplier_name\"]))\n",
    "\n",
    "# Divide a date em year, month, day\n",
    "df_sales = df_sales.withColumn(\"year\", year(\"date\")) \\\n",
    "                   .withColumn(\"month\", month(\"date\")) \\\n",
    "                   .withColumn(\"day\", dayofmonth(\"date\"))\n",
    "\n",
    "# Muda o formato da data\n",
    "df_sales = df_sales.withColumn(\"date\", date_format(\"date\", \"yyyyMMdd\"))\n",
    "\n",
    "\n",
    "# Join suppliers com states, troca a coluna states por states_id\n",
    "df_joined_sup_st = df_suppliers.join(df_states, df_suppliers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_suppliers = df_joined_sup_st.select(\"supplier_id\", \"supplier_name\", \"email\",\"state_id\")\n",
    "#df_suppliers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em sellers\n",
    "df_sellers = df_sellers.withColumn(\"email\", upper(df_sellers[\"email\"])) \\\n",
    "                       .withColumn(\"seller_name\", upper(df_sellers[\"seller_name\"]))\n",
    "\n",
    "# Join sellers com states, troca a coluna states por states_id\n",
    "df_joined_se_st = df_sellers.join(df_states, df_sellers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_sellers = df_joined_se_st.select(\"seller_id\", \"seller_name\", \"email\",\"state_id\")\n",
    "#df_sellers.show()\n",
    "\n",
    "# Fazendo upper em supplier_name e email em customers\n",
    "df_customers = df_customers.withColumn(\"email\", upper(df_customers[\"email\"])) \\\n",
    "                           .withColumn(\"customer_name\", upper(df_customers[\"customer_name\"]))\n",
    "\n",
    "# Join customers com states, troca a coluna states por states_id\n",
    "df_joined_cu_st = df_customers.join(df_states, df_customers[\"state\"] == df_states[\"state_acronym\"], \"inner\")\n",
    "df_customers = df_joined_cu_st.select(\"customer_id\", \"customer_name\", \"email\",\"state_id\")\n",
    "#df_customers.show()\n",
    "\n",
    "# Fazendo upper em product_name em products\n",
    "df_products = df_products.withColumn(\"product_name\", upper(df_products[\"product_name\"]))\n",
    "\n",
    "# Join entre products e suppliers\n",
    "df_products = df_products.drop(\"price\")\n",
    "df_joined_products_suppliers = df_products.join(df_suppliers, \"supplier_id\")\n",
    "#df_joined_products_suppliers.show()\n",
    "\n",
    "# Fazendo upper em category_name em categories\n",
    "df_categories = df_categories.withColumn(\"category_name\", upper(df_categories[\"category_name\"]))\n",
    "\n",
    "# Join com categories\n",
    "df_joined_products_suppliers_categories = df_joined_products_suppliers.join(df_categories, \"category_id\")\n",
    "#df_joined_products_suppliers_categories.show()\n",
    "\n",
    "#Join com sales_items\n",
    "df_joined_prod_sup_cat_si = df_joined_products_suppliers_categories.join(df_sales_items, \"product_id\")\n",
    "#df_joined_prod_sup_cat_si.show()\n",
    "\n",
    "#join com sales\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si.join(df_sales, \"sales_id\")\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "\n",
    "# Calculando total_price baseado em price * quantity\n",
    "df_joined_prod_sup_cat_si_sa = df_joined_prod_sup_cat_si_sa.withColumn(\"total_price\", col(\"price\") * col(\"quantity\"))\n",
    "#df_joined_prod_sup_cat_si_sa.show()\n",
    "\n",
    "# Fechar a sessão do Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
